{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-22T07:32:37.351415Z",
     "iopub.status.busy": "2020-11-22T07:32:37.350609Z",
     "iopub.status.idle": "2020-11-22T07:32:42.731709Z",
     "shell.execute_reply": "2020-11-22T07:32:42.732937Z"
    },
    "papermill": {
     "duration": 5.404523,
     "end_time": "2020-11-22T07:32:42.733160",
     "exception": false,
     "start_time": "2020-11-22T07:32:37.328637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np   \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import keras, math\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017532,
     "end_time": "2020-11-22T07:32:42.767725",
     "exception": false,
     "start_time": "2020-11-22T07:32:42.750193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing Functions for Adience Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-22T07:32:42.810812Z",
     "iopub.status.busy": "2020-11-22T07:32:42.809981Z",
     "iopub.status.idle": "2020-11-22T07:32:42.815108Z",
     "shell.execute_reply": "2020-11-22T07:32:42.816209Z"
    },
    "papermill": {
     "duration": 0.032877,
     "end_time": "2020-11-22T07:32:42.816368",
     "exception": false,
     "start_time": "2020-11-22T07:32:42.783491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_path(df, basepath):\n",
    "    \"\"\"\n",
    "    this function creates column of image file path for each image\n",
    "    \"\"\"\n",
    "    df['path'] = df.apply(lambda x: f\"{basepath}{x['user_id']}/landmark_aligned_face.{x['face_id']}.{x['original_image']}\", axis=1)\n",
    "    return df\n",
    "\n",
    "def filter_df(df):\n",
    "    \"\"\"\n",
    "    this function removes images with unknown gender from the dataset\n",
    "    \"\"\"\n",
    "    df['valid'] = df['gender'].apply(lambda x: int(x in ['f', 'm']))\n",
    "    df = df[df['valid'] == 1]\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def flow_ready(df):\n",
    "    \"\"\"\n",
    "    this function will make a dataframe ready for flow with cols: [image_path, category]\n",
    "    \"\"\"\n",
    "    df = pd.concat([df['path'],df['gender']],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014903,
     "end_time": "2020-11-22T07:32:42.847483",
     "exception": false,
     "start_time": "2020-11-22T07:32:42.832580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T07:32:42.889748Z",
     "iopub.status.busy": "2020-11-22T07:32:42.887166Z",
     "iopub.status.idle": "2020-11-22T07:32:43.553401Z",
     "shell.execute_reply": "2020-11-22T07:32:43.552315Z"
    },
    "papermill": {
     "duration": 0.690538,
     "end_time": "2020-11-22T07:32:43.553523",
     "exception": false,
     "start_time": "2020-11-22T07:32:42.862985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/adience-age-gender-prediction-aligned...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/adience-age-gender-prediction-aligned...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/adience-age-gender-prediction-aligned...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/adience-age-gender-prediction-aligned...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/adience-age-gender-prediction-aligned...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path gender\n",
       "0  ../input/adience-age-gender-prediction-aligned...      f\n",
       "1  ../input/adience-age-gender-prediction-aligned...      m\n",
       "2  ../input/adience-age-gender-prediction-aligned...      f\n",
       "3  ../input/adience-age-gender-prediction-aligned...      m\n",
       "4  ../input/adience-age-gender-prediction-aligned...      m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = \"../input/adience-age-gender-prediction-aligned-faces/age-gender-data/\"\n",
    "img_folder = \"../input/adience-age-gender-prediction-aligned-faces/age-gender-data/aligned/\"\n",
    "\n",
    "fold0_df = pd.read_csv(f\"{data_folder}fold_{0}_data.txt\", sep=\"\\t\")\n",
    "fold1_df = pd.read_csv(f\"{data_folder}fold_{1}_data.txt\", sep=\"\\t\")\n",
    "fold2_df = pd.read_csv(f\"{data_folder}fold_{2}_data.txt\", sep=\"\\t\")\n",
    "fold3_df = pd.read_csv(f\"{data_folder}fold_{3}_data.txt\", sep=\"\\t\")\n",
    "fold4_df = pd.read_csv(f\"{data_folder}fold_{4}_data.txt\", sep=\"\\t\")\n",
    "\n",
    "# remove unknown genders\n",
    "fold0_df = filter_df(fold0_df)\n",
    "fold1_df = filter_df(fold1_df)\n",
    "fold2_df = filter_df(fold2_df)\n",
    "fold3_df = filter_df(fold3_df)\n",
    "fold4_df = filter_df(fold4_df)\n",
    "\n",
    "# create image file path for each image in dataset\n",
    "# create image_path, label dataframe for image generator\n",
    "fold0_df = flow_ready(create_path(fold0_df, img_folder))\n",
    "fold1_df = flow_ready(create_path(fold1_df, img_folder))\n",
    "fold2_df = flow_ready(create_path(fold2_df, img_folder))\n",
    "fold3_df = flow_ready(create_path(fold3_df, img_folder))\n",
    "fold4_df = flow_ready(create_path(fold4_df, img_folder))\n",
    "\n",
    "# initial train test set\n",
    "train_df = pd.concat([fold0_df, fold2_df, fold3_df, fold4_df])\n",
    "test_df = fold1_df\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012242,
     "end_time": "2020-11-22T07:32:43.578576",
     "exception": false,
     "start_time": "2020-11-22T07:32:43.566334",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T07:32:43.619476Z",
     "iopub.status.busy": "2020-11-22T07:32:43.617491Z",
     "iopub.status.idle": "2020-11-22T07:32:43.622208Z",
     "shell.execute_reply": "2020-11-22T07:32:43.621673Z"
    },
    "papermill": {
     "duration": 0.030934,
     "end_time": "2020-11-22T07:32:43.622324",
     "exception": false,
     "start_time": "2020-11-22T07:32:43.591390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CutOutDataGenerator(ImageDataGenerator):\n",
    "    def __init__(self,\n",
    "                 cutout_size=None,\n",
    "                 n_squares=None,\n",
    "                 **kwargs):\n",
    "        '''\n",
    "        Custom image data generator for cutout regularization.\n",
    "        Behaves like ImageDataGenerator, but allows color augmentation.\n",
    "        '''\n",
    "        super().__init__(\n",
    "            preprocessing_function=self.augment_cutout,\n",
    "            **kwargs)\n",
    "\n",
    "        self.cutout_size = cutout_size\n",
    "        self.n_squares = n_squares\n",
    "    \n",
    "    def augment_cutout(self, image):\n",
    "        '''Takes an input image and returns a cutout version of it'''\n",
    "        h, w, channels = image.shape\n",
    "        new_image = image\n",
    "        for _ in range(self.n_squares):\n",
    "            y = tf.random.uniform([1], minval=0, maxval=h, dtype=tf.int32).numpy()[0]\n",
    "            x = tf.random.uniform([1], minval=0, maxval=w, dtype=tf.int32).numpy()[0]\n",
    "            y1 = tf.clip_by_value(y - self.cutout_size // 2, 0, h).numpy()\n",
    "            y2 = tf.clip_by_value(y + self.cutout_size // 2, 0, h).numpy()\n",
    "            x1 = tf.clip_by_value(x - self.cutout_size // 2, 0, w).numpy()\n",
    "            x2 = tf.clip_by_value(x + self.cutout_size // 2, 0, w).numpy()\n",
    "            new_image[y1:y2,x1:x2,:] = 0\n",
    "        return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T07:32:43.654031Z",
     "iopub.status.busy": "2020-11-22T07:32:43.652214Z",
     "iopub.status.idle": "2020-11-22T07:32:43.654909Z",
     "shell.execute_reply": "2020-11-22T07:32:43.655492Z"
    },
    "papermill": {
     "duration": 0.02023,
     "end_time": "2020-11-22T07:32:43.655608",
     "exception": false,
     "start_time": "2020-11-22T07:32:43.635378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# based on pre-trained base\n",
    "image_size = (218, 178)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T07:32:43.687585Z",
     "iopub.status.busy": "2020-11-22T07:32:43.686906Z",
     "iopub.status.idle": "2020-11-22T07:32:43.690407Z",
     "shell.execute_reply": "2020-11-22T07:32:43.689933Z"
    },
    "papermill": {
     "duration": 0.02177,
     "end_time": "2020-11-22T07:32:43.690493",
     "exception": false,
     "start_time": "2020-11-22T07:32:43.668723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_datagen = CutOutDataGenerator(rotation_range = 6,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   rescale = 1./255.,\n",
    "                                   horizontal_flip = True,\n",
    "                                   cutout_size=40, n_squares=1)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T07:32:43.762295Z",
     "iopub.status.busy": "2020-11-22T07:32:43.746974Z",
     "iopub.status.idle": "2020-11-22T07:32:47.234802Z",
     "shell.execute_reply": "2020-11-22T07:32:47.234248Z"
    },
    "papermill": {
     "duration": 3.531982,
     "end_time": "2020-11-22T07:32:47.234928",
     "exception": false,
     "start_time": "2020-11-22T07:32:43.702946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13883 validated image filenames belonging to 2 classes.\n",
      "Found 3609 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                            x_col=train_df.columns[0],\n",
    "                                            y_col=train_df.columns[1],\n",
    "                                            batch_size=batch_size,\n",
    "                                            seed=42,\n",
    "                                            shuffle=True,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            target_size=image_size,\n",
    "                                            color_mode='rgb')\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(dataframe=test_df,\n",
    "                                            x_col=test_df.columns[0],\n",
    "                                            y_col=test_df.columns[1],\n",
    "                                            batch_size=batch_size,\n",
    "                                            seed=42,\n",
    "                                            shuffle=True,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            target_size=image_size,\n",
    "                                            color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T07:32:47.267505Z",
     "iopub.status.busy": "2020-11-22T07:32:47.266822Z",
     "iopub.status.idle": "2020-11-22T07:32:53.918067Z",
     "shell.execute_reply": "2020-11-22T07:32:53.916885Z"
    },
    "papermill": {
     "duration": 6.668809,
     "end_time": "2020-11-22T07:32:53.918234",
     "exception": false,
     "start_time": "2020-11-22T07:32:47.249425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inceptionv3_celeba = \"../input/image-recognition-gender-detection-inceptionv3/weights.best.inc.male.hdf5\"\n",
    "pretrained_model = load_model(inceptionv3_celeba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014604,
     "end_time": "2020-11-22T07:32:53.947754",
     "exception": false,
     "start_time": "2020-11-22T07:32:53.933150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T07:32:53.986421Z",
     "iopub.status.busy": "2020-11-22T07:32:53.984606Z",
     "iopub.status.idle": "2020-11-22T07:32:53.987466Z",
     "shell.execute_reply": "2020-11-22T07:32:53.988035Z"
    },
    "papermill": {
     "duration": 0.026306,
     "end_time": "2020-11-22T07:32:53.988155",
     "exception": false,
     "start_time": "2020-11-22T07:32:53.961849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('cutout_model_fold1.h5',\n",
    "                             monitor='val_accuracy', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max')\n",
    "\n",
    "def step_decay(epoch):\n",
    "    if epoch < 10:\n",
    "        lrate = 0.01\n",
    "    else:\n",
    "        initial_lrate = 0.005\n",
    "        drop = 0.5\n",
    "        epochs_drop = 10.0\n",
    "        lrate = initial_lrate * math.pow(drop, \n",
    "                math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "  \n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list= [checkpoint, lrate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T07:32:54.020494Z",
     "iopub.status.busy": "2020-11-22T07:32:54.019819Z",
     "iopub.status.idle": "2020-11-22T07:32:54.023462Z",
     "shell.execute_reply": "2020-11-22T07:32:54.024568Z"
    },
    "papermill": {
     "duration": 0.023128,
     "end_time": "2020-11-22T07:32:54.024715",
     "exception": false,
     "start_time": "2020-11-22T07:32:54.001587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_STEP_SIZE = train_generator.n//train_generator.batch_size\n",
    "VAL_STEP_SIZE = val_generator.n//val_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T07:32:54.062802Z",
     "iopub.status.busy": "2020-11-22T07:32:54.061773Z",
     "iopub.status.idle": "2020-11-22T10:35:24.413689Z",
     "shell.execute_reply": "2020-11-22T10:35:24.414411Z"
    },
    "papermill": {
     "duration": 10950.375065,
     "end_time": "2020-11-22T10:35:24.414638",
     "exception": false,
     "start_time": "2020-11-22T07:32:54.039573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.2944 - accuracy: 0.8708\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.86747, saving model to cutout_model_fold1.h5\n",
      "433/433 [==============================] - 396s 914ms/step - loss: 0.2944 - accuracy: 0.8708 - val_loss: 0.4030 - val_accuracy: 0.8675\n",
      "Epoch 2/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.9271\n",
      "Epoch 00002: val_accuracy improved from 0.86747 to 0.89007, saving model to cutout_model_fold1.h5\n",
      "433/433 [==============================] - 361s 834ms/step - loss: 0.1886 - accuracy: 0.9271 - val_loss: 0.2631 - val_accuracy: 0.8901\n",
      "Epoch 3/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.9469\n",
      "Epoch 00003: val_accuracy did not improve from 0.89007\n",
      "433/433 [==============================] - 359s 829ms/step - loss: 0.1393 - accuracy: 0.9469 - val_loss: 0.3453 - val_accuracy: 0.8686\n",
      "Epoch 4/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.1213 - accuracy: 0.9560\n",
      "Epoch 00004: val_accuracy did not improve from 0.89007\n",
      "433/433 [==============================] - 369s 852ms/step - loss: 0.1213 - accuracy: 0.9560 - val_loss: 0.3751 - val_accuracy: 0.8781\n",
      "Epoch 5/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.9631\n",
      "Epoch 00005: val_accuracy improved from 0.89007 to 0.91546, saving model to cutout_model_fold1.h5\n",
      "433/433 [==============================] - 355s 820ms/step - loss: 0.1052 - accuracy: 0.9631 - val_loss: 0.2588 - val_accuracy: 0.9155\n",
      "Epoch 6/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9693\n",
      "Epoch 00006: val_accuracy did not improve from 0.91546\n",
      "433/433 [==============================] - 352s 813ms/step - loss: 0.0843 - accuracy: 0.9693 - val_loss: 0.2346 - val_accuracy: 0.9143\n",
      "Epoch 7/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9698\n",
      "Epoch 00007: val_accuracy did not improve from 0.91546\n",
      "433/433 [==============================] - 356s 821ms/step - loss: 0.0785 - accuracy: 0.9698 - val_loss: 0.3897 - val_accuracy: 0.8725\n",
      "Epoch 8/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9754\n",
      "Epoch 00008: val_accuracy did not improve from 0.91546\n",
      "433/433 [==============================] - 356s 821ms/step - loss: 0.0686 - accuracy: 0.9754 - val_loss: 0.3125 - val_accuracy: 0.9118\n",
      "Epoch 9/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9768\n",
      "Epoch 00009: val_accuracy did not improve from 0.91546\n",
      "433/433 [==============================] - 355s 819ms/step - loss: 0.0651 - accuracy: 0.9768 - val_loss: 0.2942 - val_accuracy: 0.9116\n",
      "Epoch 10/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9794\n",
      "Epoch 00010: val_accuracy did not improve from 0.91546\n",
      "433/433 [==============================] - 353s 815ms/step - loss: 0.0614 - accuracy: 0.9794 - val_loss: 0.3269 - val_accuracy: 0.8987\n",
      "Epoch 11/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9872\n",
      "Epoch 00011: val_accuracy improved from 0.91546 to 0.92160, saving model to cutout_model_fold1.h5\n",
      "433/433 [==============================] - 356s 823ms/step - loss: 0.0390 - accuracy: 0.9872 - val_loss: 0.2921 - val_accuracy: 0.9216\n",
      "Epoch 12/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9897\n",
      "Epoch 00012: val_accuracy did not improve from 0.92160\n",
      "433/433 [==============================] - 357s 824ms/step - loss: 0.0310 - accuracy: 0.9897 - val_loss: 0.2922 - val_accuracy: 0.9205\n",
      "Epoch 13/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9918\n",
      "Epoch 00013: val_accuracy improved from 0.92160 to 0.92522, saving model to cutout_model_fold1.h5\n",
      "433/433 [==============================] - 364s 840ms/step - loss: 0.0234 - accuracy: 0.9918 - val_loss: 0.2808 - val_accuracy: 0.9252\n",
      "Epoch 14/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9925\n",
      "Epoch 00014: val_accuracy did not improve from 0.92522\n",
      "433/433 [==============================] - 358s 826ms/step - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.3351 - val_accuracy: 0.9213\n",
      "Epoch 15/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9938\n",
      "Epoch 00015: val_accuracy improved from 0.92522 to 0.92801, saving model to cutout_model_fold1.h5\n",
      "433/433 [==============================] - 368s 849ms/step - loss: 0.0175 - accuracy: 0.9938 - val_loss: 0.3182 - val_accuracy: 0.9280\n",
      "Epoch 16/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9928\n",
      "Epoch 00016: val_accuracy did not improve from 0.92801\n",
      "433/433 [==============================] - 368s 851ms/step - loss: 0.0199 - accuracy: 0.9928 - val_loss: 0.3160 - val_accuracy: 0.9244\n",
      "Epoch 17/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9944\n",
      "Epoch 00017: val_accuracy did not improve from 0.92801\n",
      "433/433 [==============================] - 361s 834ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.3211 - val_accuracy: 0.9244\n",
      "Epoch 18/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9934\n",
      "Epoch 00018: val_accuracy did not improve from 0.92801\n",
      "433/433 [==============================] - 362s 836ms/step - loss: 0.0178 - accuracy: 0.9934 - val_loss: 0.3607 - val_accuracy: 0.9118\n",
      "Epoch 19/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9960\n",
      "Epoch 00019: val_accuracy did not improve from 0.92801\n",
      "433/433 [==============================] - 362s 835ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.3643 - val_accuracy: 0.9249\n",
      "Epoch 20/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9950\n",
      "Epoch 00020: val_accuracy did not improve from 0.92801\n",
      "433/433 [==============================] - 360s 832ms/step - loss: 0.0121 - accuracy: 0.9950 - val_loss: 0.3516 - val_accuracy: 0.9227\n",
      "Epoch 21/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9960\n",
      "Epoch 00021: val_accuracy did not improve from 0.92801\n",
      "433/433 [==============================] - 363s 838ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 0.3522 - val_accuracy: 0.9238\n",
      "Epoch 22/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9958\n",
      "Epoch 00022: val_accuracy improved from 0.92801 to 0.92829, saving model to cutout_model_fold1.h5\n",
      "433/433 [==============================] - 365s 842ms/step - loss: 0.0107 - accuracy: 0.9958 - val_loss: 0.3457 - val_accuracy: 0.9283\n",
      "Epoch 23/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9957\n",
      "Epoch 00023: val_accuracy did not improve from 0.92829\n",
      "433/433 [==============================] - 369s 851ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.3369 - val_accuracy: 0.9277\n",
      "Epoch 24/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9963\n",
      "Epoch 00024: val_accuracy did not improve from 0.92829\n",
      "433/433 [==============================] - 385s 890ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.3686 - val_accuracy: 0.9261\n",
      "Epoch 25/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9971\n",
      "Epoch 00025: val_accuracy did not improve from 0.92829\n",
      "433/433 [==============================] - 374s 864ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.3995 - val_accuracy: 0.9219\n",
      "Epoch 26/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9962\n",
      "Epoch 00026: val_accuracy did not improve from 0.92829\n",
      "433/433 [==============================] - 371s 857ms/step - loss: 0.0104 - accuracy: 0.9962 - val_loss: 0.3955 - val_accuracy: 0.9224\n",
      "Epoch 27/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9969\n",
      "Epoch 00027: val_accuracy did not improve from 0.92829\n",
      "433/433 [==============================] - 368s 850ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.3920 - val_accuracy: 0.9224\n",
      "Epoch 28/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9975\n",
      "Epoch 00028: val_accuracy did not improve from 0.92829\n",
      "433/433 [==============================] - 363s 838ms/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.4055 - val_accuracy: 0.9230\n",
      "Epoch 29/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9976\n",
      "Epoch 00029: val_accuracy did not improve from 0.92829\n",
      "433/433 [==============================] - 357s 823ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.4353 - val_accuracy: 0.9208\n",
      "Epoch 30/30\n",
      "433/433 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9973\n",
      "Epoch 00030: val_accuracy did not improve from 0.92829\n",
      "433/433 [==============================] - 360s 832ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.4175 - val_accuracy: 0.9235\n"
     ]
    }
   ],
   "source": [
    "history = pretrained_model.fit(train_generator,\n",
    "          steps_per_epoch=TRAIN_STEP_SIZE,\n",
    "          epochs=30,\n",
    "          validation_data=val_generator,\n",
    "          validation_steps=VAL_STEP_SIZE,\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-22T10:35:34.159958Z",
     "iopub.status.busy": "2020-11-22T10:35:34.159048Z",
     "iopub.status.idle": "2020-11-22T10:35:34.165113Z",
     "shell.execute_reply": "2020-11-22T10:35:34.164533Z"
    },
    "papermill": {
     "duration": 5.064201,
     "end_time": "2020-11-22T10:35:34.165234",
     "exception": false,
     "start_time": "2020-11-22T10:35:29.101033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(\"fold1_validation.npy\", history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 10987.306136,
   "end_time": "2020-11-22T10:35:40.417503",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-22T07:32:33.111367",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
