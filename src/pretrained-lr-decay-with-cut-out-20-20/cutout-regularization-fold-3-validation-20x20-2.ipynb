{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-21T09:38:28.895638Z",
     "iopub.status.busy": "2020-11-21T09:38:28.894790Z",
     "iopub.status.idle": "2020-11-21T09:38:34.537033Z",
     "shell.execute_reply": "2020-11-21T09:38:34.536372Z"
    },
    "papermill": {
     "duration": 5.664796,
     "end_time": "2020-11-21T09:38:34.537180",
     "exception": false,
     "start_time": "2020-11-21T09:38:28.872384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np   \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import keras, math\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011115,
     "end_time": "2020-11-21T09:38:34.560856",
     "exception": false,
     "start_time": "2020-11-21T09:38:34.549741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing Functions for Adience Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-21T09:38:34.593808Z",
     "iopub.status.busy": "2020-11-21T09:38:34.593046Z",
     "iopub.status.idle": "2020-11-21T09:38:34.596676Z",
     "shell.execute_reply": "2020-11-21T09:38:34.596143Z"
    },
    "papermill": {
     "duration": 0.024327,
     "end_time": "2020-11-21T09:38:34.596809",
     "exception": false,
     "start_time": "2020-11-21T09:38:34.572482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_path(df, basepath):\n",
    "    \"\"\"\n",
    "    this function creates column of image file path for each image\n",
    "    \"\"\"\n",
    "    df['path'] = df.apply(lambda x: f\"{basepath}{x['user_id']}/landmark_aligned_face.{x['face_id']}.{x['original_image']}\", axis=1)\n",
    "    return df\n",
    "\n",
    "def filter_df(df):\n",
    "    \"\"\"\n",
    "    this function removes images with unknown gender from the dataset\n",
    "    \"\"\"\n",
    "    df['valid'] = df['gender'].apply(lambda x: int(x in ['f', 'm']))\n",
    "    df = df[df['valid'] == 1]\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def flow_ready(df):\n",
    "    \"\"\"\n",
    "    this function will make a dataframe ready for flow with cols: [image_path, category]\n",
    "    \"\"\"\n",
    "    df = pd.concat([df['path'],df['gender']],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01127,
     "end_time": "2020-11-21T09:38:34.619763",
     "exception": false,
     "start_time": "2020-11-21T09:38:34.608493",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T09:38:34.657967Z",
     "iopub.status.busy": "2020-11-21T09:38:34.657266Z",
     "iopub.status.idle": "2020-11-21T09:38:35.280721Z",
     "shell.execute_reply": "2020-11-21T09:38:35.281299Z"
    },
    "papermill": {
     "duration": 0.650411,
     "end_time": "2020-11-21T09:38:35.281451",
     "exception": false,
     "start_time": "2020-11-21T09:38:34.631040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/adience-age-gender-prediction-aligned...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/adience-age-gender-prediction-aligned...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/adience-age-gender-prediction-aligned...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/adience-age-gender-prediction-aligned...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/adience-age-gender-prediction-aligned...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path gender\n",
       "0  ../input/adience-age-gender-prediction-aligned...      f\n",
       "1  ../input/adience-age-gender-prediction-aligned...      m\n",
       "2  ../input/adience-age-gender-prediction-aligned...      f\n",
       "3  ../input/adience-age-gender-prediction-aligned...      m\n",
       "4  ../input/adience-age-gender-prediction-aligned...      m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = \"../input/adience-age-gender-prediction-aligned-faces/age-gender-data/\"\n",
    "img_folder = \"../input/adience-age-gender-prediction-aligned-faces/age-gender-data/aligned/\"\n",
    "\n",
    "fold0_df = pd.read_csv(f\"{data_folder}fold_{0}_data.txt\", sep=\"\\t\")\n",
    "fold1_df = pd.read_csv(f\"{data_folder}fold_{1}_data.txt\", sep=\"\\t\")\n",
    "fold2_df = pd.read_csv(f\"{data_folder}fold_{2}_data.txt\", sep=\"\\t\")\n",
    "fold3_df = pd.read_csv(f\"{data_folder}fold_{3}_data.txt\", sep=\"\\t\")\n",
    "fold4_df = pd.read_csv(f\"{data_folder}fold_{4}_data.txt\", sep=\"\\t\")\n",
    "\n",
    "# remove unknown genders\n",
    "fold0_df = filter_df(fold0_df)\n",
    "fold1_df = filter_df(fold1_df)\n",
    "fold2_df = filter_df(fold2_df)\n",
    "fold3_df = filter_df(fold3_df)\n",
    "fold4_df = filter_df(fold4_df)\n",
    "\n",
    "# create image file path for each image in dataset\n",
    "# create image_path, label dataframe for image generator\n",
    "fold0_df = flow_ready(create_path(fold0_df, img_folder))\n",
    "fold1_df = flow_ready(create_path(fold1_df, img_folder))\n",
    "fold2_df = flow_ready(create_path(fold2_df, img_folder))\n",
    "fold3_df = flow_ready(create_path(fold3_df, img_folder))\n",
    "fold4_df = flow_ready(create_path(fold4_df, img_folder))\n",
    "\n",
    "# initial train test set\n",
    "train_df = pd.concat([fold0_df, fold1_df, fold2_df, fold4_df])\n",
    "test_df = fold3_df\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013143,
     "end_time": "2020-11-21T09:38:35.308227",
     "exception": false,
     "start_time": "2020-11-21T09:38:35.295084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T09:38:35.351018Z",
     "iopub.status.busy": "2020-11-21T09:38:35.348467Z",
     "iopub.status.idle": "2020-11-21T09:38:35.353985Z",
     "shell.execute_reply": "2020-11-21T09:38:35.353400Z"
    },
    "papermill": {
     "duration": 0.032615,
     "end_time": "2020-11-21T09:38:35.354103",
     "exception": false,
     "start_time": "2020-11-21T09:38:35.321488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CutOutDataGenerator(ImageDataGenerator):\n",
    "    def __init__(self,\n",
    "                 cutout_size=None,\n",
    "                 n_squares=None,\n",
    "                 **kwargs):\n",
    "        '''\n",
    "        Custom image data generator for cutout regularization.\n",
    "        Behaves like ImageDataGenerator, but allows color augmentation.\n",
    "        '''\n",
    "        super().__init__(\n",
    "            preprocessing_function=self.augment_cutout,\n",
    "            **kwargs)\n",
    "\n",
    "        self.cutout_size = cutout_size\n",
    "        self.n_squares = n_squares\n",
    "    \n",
    "    def augment_cutout(self, image):\n",
    "        '''Takes an input image and returns a cutout version of it'''\n",
    "        h, w, channels = image.shape\n",
    "        new_image = image\n",
    "        for _ in range(self.n_squares):\n",
    "            y = tf.random.uniform([1], minval=0, maxval=h, dtype=tf.int32).numpy()[0]\n",
    "            x = tf.random.uniform([1], minval=0, maxval=w, dtype=tf.int32).numpy()[0]\n",
    "            y1 = tf.clip_by_value(y - self.cutout_size // 2, 0, h).numpy()\n",
    "            y2 = tf.clip_by_value(y + self.cutout_size // 2, 0, h).numpy()\n",
    "            x1 = tf.clip_by_value(x - self.cutout_size // 2, 0, w).numpy()\n",
    "            x2 = tf.clip_by_value(x + self.cutout_size // 2, 0, w).numpy()\n",
    "            new_image[y1:y2,x1:x2,:] = 0\n",
    "        return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T09:38:35.385791Z",
     "iopub.status.busy": "2020-11-21T09:38:35.385074Z",
     "iopub.status.idle": "2020-11-21T09:38:35.389891Z",
     "shell.execute_reply": "2020-11-21T09:38:35.389276Z"
    },
    "papermill": {
     "duration": 0.0224,
     "end_time": "2020-11-21T09:38:35.389998",
     "exception": false,
     "start_time": "2020-11-21T09:38:35.367598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# based on pre-trained base\n",
    "image_size = (218, 178)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T09:38:35.424035Z",
     "iopub.status.busy": "2020-11-21T09:38:35.423221Z",
     "iopub.status.idle": "2020-11-21T09:38:35.427977Z",
     "shell.execute_reply": "2020-11-21T09:38:35.427355Z"
    },
    "papermill": {
     "duration": 0.024403,
     "end_time": "2020-11-21T09:38:35.428085",
     "exception": false,
     "start_time": "2020-11-21T09:38:35.403682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_datagen = CutOutDataGenerator(rotation_range = 6,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   rescale = 1./255.,\n",
    "                                   horizontal_flip = True,\n",
    "                                   cutout_size=20, n_squares=2)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T09:38:35.494084Z",
     "iopub.status.busy": "2020-11-21T09:38:35.488969Z",
     "iopub.status.idle": "2020-11-21T09:38:39.778619Z",
     "shell.execute_reply": "2020-11-21T09:38:39.778022Z"
    },
    "papermill": {
     "duration": 4.336956,
     "end_time": "2020-11-21T09:38:39.778758",
     "exception": false,
     "start_time": "2020-11-21T09:38:35.441802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14186 validated image filenames belonging to 2 classes.\n",
      "Found 3306 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                            x_col=train_df.columns[0],\n",
    "                                            y_col=train_df.columns[1],\n",
    "                                            batch_size=batch_size,\n",
    "                                            seed=42,\n",
    "                                            shuffle=True,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            target_size=image_size,\n",
    "                                            color_mode='rgb')\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(dataframe=test_df,\n",
    "                                            x_col=test_df.columns[0],\n",
    "                                            y_col=test_df.columns[1],\n",
    "                                            batch_size=batch_size,\n",
    "                                            seed=42,\n",
    "                                            shuffle=True,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            target_size=image_size,\n",
    "                                            color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T09:38:39.812525Z",
     "iopub.status.busy": "2020-11-21T09:38:39.811886Z",
     "iopub.status.idle": "2020-11-21T09:38:46.993278Z",
     "shell.execute_reply": "2020-11-21T09:38:46.992525Z"
    },
    "papermill": {
     "duration": 7.199979,
     "end_time": "2020-11-21T09:38:46.993411",
     "exception": false,
     "start_time": "2020-11-21T09:38:39.793432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inceptionv3_celeba = \"../input/image-recognition-gender-detection-inceptionv3/weights.best.inc.male.hdf5\"\n",
    "pretrained_model = load_model(inceptionv3_celeba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015088,
     "end_time": "2020-11-21T09:38:47.023766",
     "exception": false,
     "start_time": "2020-11-21T09:38:47.008678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T09:38:47.063412Z",
     "iopub.status.busy": "2020-11-21T09:38:47.062316Z",
     "iopub.status.idle": "2020-11-21T09:38:47.066222Z",
     "shell.execute_reply": "2020-11-21T09:38:47.065516Z"
    },
    "papermill": {
     "duration": 0.027698,
     "end_time": "2020-11-21T09:38:47.066350",
     "exception": false,
     "start_time": "2020-11-21T09:38:47.038652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('cutout_model_fold3.h5',\n",
    "                             monitor='val_accuracy', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max')\n",
    "\n",
    "def step_decay(epoch):\n",
    "    if epoch < 10:\n",
    "        lrate = 0.01\n",
    "    else:\n",
    "        initial_lrate = 0.005\n",
    "        drop = 0.5\n",
    "        epochs_drop = 10.0\n",
    "        lrate = initial_lrate * math.pow(drop, \n",
    "                math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "  \n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list= [checkpoint, lrate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T09:38:47.101436Z",
     "iopub.status.busy": "2020-11-21T09:38:47.100659Z",
     "iopub.status.idle": "2020-11-21T09:38:47.104829Z",
     "shell.execute_reply": "2020-11-21T09:38:47.105460Z"
    },
    "papermill": {
     "duration": 0.024147,
     "end_time": "2020-11-21T09:38:47.105607",
     "exception": false,
     "start_time": "2020-11-21T09:38:47.081460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_STEP_SIZE = train_generator.n//train_generator.batch_size\n",
    "VAL_STEP_SIZE = val_generator.n//val_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T09:38:47.143817Z",
     "iopub.status.busy": "2020-11-21T09:38:47.142791Z",
     "iopub.status.idle": "2020-11-21T13:12:27.110295Z",
     "shell.execute_reply": "2020-11-21T13:12:27.111099Z"
    },
    "papermill": {
     "duration": 12819.990526,
     "end_time": "2020-11-21T13:12:27.111339",
     "exception": false,
     "start_time": "2020-11-21T09:38:47.120813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.3114 - accuracy: 0.8627\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82433, saving model to cutout_model_fold3.h5\n",
      "443/443 [==============================] - 480s 1s/step - loss: 0.3114 - accuracy: 0.8627 - val_loss: 0.3990 - val_accuracy: 0.8243\n",
      "Epoch 2/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.1793 - accuracy: 0.9308\n",
      "Epoch 00002: val_accuracy improved from 0.82433 to 0.92172, saving model to cutout_model_fold3.h5\n",
      "443/443 [==============================] - 449s 1s/step - loss: 0.1793 - accuracy: 0.9308 - val_loss: 0.2043 - val_accuracy: 0.9217\n",
      "Epoch 3/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.1409 - accuracy: 0.9479\n",
      "Epoch 00003: val_accuracy improved from 0.92172 to 0.93295, saving model to cutout_model_fold3.h5\n",
      "443/443 [==============================] - 451s 1s/step - loss: 0.1409 - accuracy: 0.9479 - val_loss: 0.1917 - val_accuracy: 0.9329\n",
      "Epoch 4/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.1187 - accuracy: 0.9557\n",
      "Epoch 00004: val_accuracy did not improve from 0.93295\n",
      "443/443 [==============================] - 452s 1s/step - loss: 0.1187 - accuracy: 0.9557 - val_loss: 0.3333 - val_accuracy: 0.8905\n",
      "Epoch 5/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.9669\n",
      "Epoch 00005: val_accuracy did not improve from 0.93295\n",
      "443/443 [==============================] - 460s 1s/step - loss: 0.0901 - accuracy: 0.9669 - val_loss: 0.4597 - val_accuracy: 0.8601\n",
      "Epoch 6/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9668\n",
      "Epoch 00006: val_accuracy did not improve from 0.93295\n",
      "443/443 [==============================] - 457s 1s/step - loss: 0.0863 - accuracy: 0.9668 - val_loss: 0.2653 - val_accuracy: 0.9269\n",
      "Epoch 7/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.9733\n",
      "Epoch 00007: val_accuracy did not improve from 0.93295\n",
      "443/443 [==============================] - 443s 1s/step - loss: 0.0724 - accuracy: 0.9733 - val_loss: 0.5999 - val_accuracy: 0.8441\n",
      "Epoch 8/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9767\n",
      "Epoch 00008: val_accuracy did not improve from 0.93295\n",
      "443/443 [==============================] - 409s 923ms/step - loss: 0.0644 - accuracy: 0.9767 - val_loss: 0.2314 - val_accuracy: 0.9260\n",
      "Epoch 9/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9790\n",
      "Epoch 00009: val_accuracy did not improve from 0.93295\n",
      "443/443 [==============================] - 402s 906ms/step - loss: 0.0594 - accuracy: 0.9790 - val_loss: 0.2815 - val_accuracy: 0.9163\n",
      "Epoch 10/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9782\n",
      "Epoch 00010: val_accuracy did not improve from 0.93295\n",
      "443/443 [==============================] - 407s 919ms/step - loss: 0.0599 - accuracy: 0.9782 - val_loss: 0.3007 - val_accuracy: 0.8962\n",
      "Epoch 11/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9898\n",
      "Epoch 00011: val_accuracy improved from 0.93295 to 0.93689, saving model to cutout_model_fold3.h5\n",
      "443/443 [==============================] - 404s 913ms/step - loss: 0.0316 - accuracy: 0.9898 - val_loss: 0.2447 - val_accuracy: 0.9369\n",
      "Epoch 12/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9929\n",
      "Epoch 00012: val_accuracy improved from 0.93689 to 0.94023, saving model to cutout_model_fold3.h5\n",
      "443/443 [==============================] - 414s 934ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.2196 - val_accuracy: 0.9402\n",
      "Epoch 13/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9918\n",
      "Epoch 00013: val_accuracy improved from 0.94023 to 0.94691, saving model to cutout_model_fold3.h5\n",
      "443/443 [==============================] - 453s 1s/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 0.2208 - val_accuracy: 0.9469\n",
      "Epoch 14/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9936\n",
      "Epoch 00014: val_accuracy did not improve from 0.94691\n",
      "443/443 [==============================] - 462s 1s/step - loss: 0.0188 - accuracy: 0.9936 - val_loss: 0.2839 - val_accuracy: 0.9333\n",
      "Epoch 15/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9942\n",
      "Epoch 00015: val_accuracy did not improve from 0.94691\n",
      "443/443 [==============================] - 447s 1s/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.2176 - val_accuracy: 0.9445\n",
      "Epoch 16/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9954\n",
      "Epoch 00016: val_accuracy did not improve from 0.94691\n",
      "443/443 [==============================] - 418s 943ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.2461 - val_accuracy: 0.9442\n",
      "Epoch 17/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9956\n",
      "Epoch 00017: val_accuracy improved from 0.94691 to 0.94873, saving model to cutout_model_fold3.h5\n",
      "443/443 [==============================] - 408s 920ms/step - loss: 0.0118 - accuracy: 0.9956 - val_loss: 0.2592 - val_accuracy: 0.9487\n",
      "Epoch 18/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9951\n",
      "Epoch 00018: val_accuracy improved from 0.94873 to 0.94933, saving model to cutout_model_fold3.h5\n",
      "443/443 [==============================] - 406s 916ms/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.2601 - val_accuracy: 0.9493\n",
      "Epoch 19/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9958\n",
      "Epoch 00019: val_accuracy improved from 0.94933 to 0.94994, saving model to cutout_model_fold3.h5\n",
      "443/443 [==============================] - 403s 910ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.2562 - val_accuracy: 0.9499\n",
      "Epoch 20/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9968\n",
      "Epoch 00020: val_accuracy did not improve from 0.94994\n",
      "443/443 [==============================] - 403s 911ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.2675 - val_accuracy: 0.9478\n",
      "Epoch 21/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9969\n",
      "Epoch 00021: val_accuracy did not improve from 0.94994\n",
      "443/443 [==============================] - 399s 901ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.2708 - val_accuracy: 0.9460\n",
      "Epoch 22/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9968\n",
      "Epoch 00022: val_accuracy did not improve from 0.94994\n",
      "443/443 [==============================] - 407s 918ms/step - loss: 0.0078 - accuracy: 0.9968 - val_loss: 0.2606 - val_accuracy: 0.9466\n",
      "Epoch 23/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9979\n",
      "Epoch 00023: val_accuracy did not improve from 0.94994\n",
      "443/443 [==============================] - 418s 944ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.2668 - val_accuracy: 0.9475\n",
      "Epoch 24/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9973\n",
      "Epoch 00024: val_accuracy did not improve from 0.94994\n",
      "443/443 [==============================] - 421s 951ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.2909 - val_accuracy: 0.9421\n",
      "Epoch 25/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9977\n",
      "Epoch 00025: val_accuracy did not improve from 0.94994\n",
      "443/443 [==============================] - 426s 962ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.2934 - val_accuracy: 0.9439\n",
      "Epoch 26/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9976\n",
      "Epoch 00026: val_accuracy did not improve from 0.94994\n",
      "443/443 [==============================] - 423s 954ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.2942 - val_accuracy: 0.9436\n",
      "Epoch 27/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9978\n",
      "Epoch 00027: val_accuracy did not improve from 0.94994\n",
      "443/443 [==============================] - 409s 922ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.2736 - val_accuracy: 0.9457\n",
      "Epoch 28/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9974\n",
      "Epoch 00028: val_accuracy did not improve from 0.94994\n",
      "443/443 [==============================] - 410s 925ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.2731 - val_accuracy: 0.9448\n",
      "Epoch 29/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9979\n",
      "Epoch 00029: val_accuracy did not improve from 0.94994\n",
      "443/443 [==============================] - 411s 928ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.3022 - val_accuracy: 0.9424\n",
      "Epoch 30/30\n",
      "443/443 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9982\n",
      "Epoch 00030: val_accuracy did not improve from 0.94994\n",
      "443/443 [==============================] - 413s 932ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.2944 - val_accuracy: 0.9421\n"
     ]
    }
   ],
   "source": [
    "history = pretrained_model.fit(train_generator,\n",
    "          steps_per_epoch=TRAIN_STEP_SIZE,\n",
    "          epochs=30,\n",
    "          validation_data=val_generator,\n",
    "          validation_steps=VAL_STEP_SIZE,\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T13:12:36.741669Z",
     "iopub.status.busy": "2020-11-21T13:12:36.739576Z",
     "iopub.status.idle": "2020-11-21T13:12:36.742382Z",
     "shell.execute_reply": "2020-11-21T13:12:36.742899Z"
    },
    "papermill": {
     "duration": 4.681059,
     "end_time": "2020-11-21T13:12:36.743036",
     "exception": false,
     "start_time": "2020-11-21T13:12:32.061977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(\"fold3_validation.npy\", history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 12858.760336,
   "end_time": "2020-11-21T13:12:43.410880",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-21T09:38:24.650544",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
