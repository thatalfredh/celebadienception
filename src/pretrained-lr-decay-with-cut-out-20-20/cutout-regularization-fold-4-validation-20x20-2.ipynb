{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-21T15:10:26.837140Z",
     "iopub.status.busy": "2020-11-21T15:10:26.836230Z",
     "iopub.status.idle": "2020-11-21T15:10:32.134949Z",
     "shell.execute_reply": "2020-11-21T15:10:32.136277Z"
    },
    "papermill": {
     "duration": 5.322602,
     "end_time": "2020-11-21T15:10:32.136712",
     "exception": false,
     "start_time": "2020-11-21T15:10:26.814110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np   \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import keras, math\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019409,
     "end_time": "2020-11-21T15:10:32.177481",
     "exception": false,
     "start_time": "2020-11-21T15:10:32.158072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing Functions for Adience Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-21T15:10:32.226282Z",
     "iopub.status.busy": "2020-11-21T15:10:32.225358Z",
     "iopub.status.idle": "2020-11-21T15:10:32.234983Z",
     "shell.execute_reply": "2020-11-21T15:10:32.236176Z"
    },
    "papermill": {
     "duration": 0.039394,
     "end_time": "2020-11-21T15:10:32.236467",
     "exception": false,
     "start_time": "2020-11-21T15:10:32.197073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_path(df, basepath):\n",
    "    \"\"\"\n",
    "    this function creates column of image file path for each image\n",
    "    \"\"\"\n",
    "    df['path'] = df.apply(lambda x: f\"{basepath}{x['user_id']}/landmark_aligned_face.{x['face_id']}.{x['original_image']}\", axis=1)\n",
    "    return df\n",
    "\n",
    "def filter_df(df):\n",
    "    \"\"\"\n",
    "    this function removes images with unknown gender from the dataset\n",
    "    \"\"\"\n",
    "    df['valid'] = df['gender'].apply(lambda x: int(x in ['f', 'm']))\n",
    "    df = df[df['valid'] == 1]\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def flow_ready(df):\n",
    "    \"\"\"\n",
    "    this function will make a dataframe ready for flow with cols: [image_path, category]\n",
    "    \"\"\"\n",
    "    df = pd.concat([df['path'],df['gender']],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017168,
     "end_time": "2020-11-21T15:10:32.272545",
     "exception": false,
     "start_time": "2020-11-21T15:10:32.255377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T15:10:32.319461Z",
     "iopub.status.busy": "2020-11-21T15:10:32.318517Z",
     "iopub.status.idle": "2020-11-21T15:10:33.217063Z",
     "shell.execute_reply": "2020-11-21T15:10:33.216147Z"
    },
    "papermill": {
     "duration": 0.927353,
     "end_time": "2020-11-21T15:10:33.217172",
     "exception": false,
     "start_time": "2020-11-21T15:10:32.289819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/adience-age-gender-prediction-aligned...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/adience-age-gender-prediction-aligned...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/adience-age-gender-prediction-aligned...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/adience-age-gender-prediction-aligned...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/adience-age-gender-prediction-aligned...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path gender\n",
       "0  ../input/adience-age-gender-prediction-aligned...      f\n",
       "1  ../input/adience-age-gender-prediction-aligned...      m\n",
       "2  ../input/adience-age-gender-prediction-aligned...      f\n",
       "3  ../input/adience-age-gender-prediction-aligned...      m\n",
       "4  ../input/adience-age-gender-prediction-aligned...      m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = \"../input/adience-age-gender-prediction-aligned-faces/age-gender-data/\"\n",
    "img_folder = \"../input/adience-age-gender-prediction-aligned-faces/age-gender-data/aligned/\"\n",
    "\n",
    "fold0_df = pd.read_csv(f\"{data_folder}fold_{0}_data.txt\", sep=\"\\t\")\n",
    "fold1_df = pd.read_csv(f\"{data_folder}fold_{1}_data.txt\", sep=\"\\t\")\n",
    "fold2_df = pd.read_csv(f\"{data_folder}fold_{2}_data.txt\", sep=\"\\t\")\n",
    "fold3_df = pd.read_csv(f\"{data_folder}fold_{3}_data.txt\", sep=\"\\t\")\n",
    "fold4_df = pd.read_csv(f\"{data_folder}fold_{4}_data.txt\", sep=\"\\t\")\n",
    "\n",
    "# remove unknown genders\n",
    "fold0_df = filter_df(fold0_df)\n",
    "fold1_df = filter_df(fold1_df)\n",
    "fold2_df = filter_df(fold2_df)\n",
    "fold3_df = filter_df(fold3_df)\n",
    "fold4_df = filter_df(fold4_df)\n",
    "\n",
    "# create image file path for each image in dataset\n",
    "# create image_path, label dataframe for image generator\n",
    "fold0_df = flow_ready(create_path(fold0_df, img_folder))\n",
    "fold1_df = flow_ready(create_path(fold1_df, img_folder))\n",
    "fold2_df = flow_ready(create_path(fold2_df, img_folder))\n",
    "fold3_df = flow_ready(create_path(fold3_df, img_folder))\n",
    "fold4_df = flow_ready(create_path(fold4_df, img_folder))\n",
    "\n",
    "# initial train test set\n",
    "train_df = pd.concat([fold0_df, fold1_df, fold2_df, fold3_df])\n",
    "test_df = fold4_df\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013033,
     "end_time": "2020-11-21T15:10:33.242722",
     "exception": false,
     "start_time": "2020-11-21T15:10:33.229689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T15:10:33.285337Z",
     "iopub.status.busy": "2020-11-21T15:10:33.283412Z",
     "iopub.status.idle": "2020-11-21T15:10:33.286187Z",
     "shell.execute_reply": "2020-11-21T15:10:33.286821Z"
    },
    "papermill": {
     "duration": 0.031211,
     "end_time": "2020-11-21T15:10:33.286970",
     "exception": false,
     "start_time": "2020-11-21T15:10:33.255759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CutOutDataGenerator(ImageDataGenerator):\n",
    "    def __init__(self,\n",
    "                 cutout_size=None,\n",
    "                 n_squares=None,\n",
    "                 **kwargs):\n",
    "        '''\n",
    "        Custom image data generator for cutout regularization.\n",
    "        Behaves like ImageDataGenerator, but allows color augmentation.\n",
    "        '''\n",
    "        super().__init__(\n",
    "            preprocessing_function=self.augment_cutout,\n",
    "            **kwargs)\n",
    "\n",
    "        self.cutout_size = cutout_size\n",
    "        self.n_squares = n_squares\n",
    "    \n",
    "    def augment_cutout(self, image):\n",
    "        '''Takes an input image and returns a cutout version of it'''\n",
    "        h, w, channels = image.shape\n",
    "        new_image = image\n",
    "        for _ in range(self.n_squares):\n",
    "            y = tf.random.uniform([1], minval=0, maxval=h, dtype=tf.int32).numpy()[0]\n",
    "            x = tf.random.uniform([1], minval=0, maxval=w, dtype=tf.int32).numpy()[0]\n",
    "            y1 = tf.clip_by_value(y - self.cutout_size // 2, 0, h).numpy()\n",
    "            y2 = tf.clip_by_value(y + self.cutout_size // 2, 0, h).numpy()\n",
    "            x1 = tf.clip_by_value(x - self.cutout_size // 2, 0, w).numpy()\n",
    "            x2 = tf.clip_by_value(x + self.cutout_size // 2, 0, w).numpy()\n",
    "            new_image[y1:y2,x1:x2,:] = 0\n",
    "        return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T15:10:33.320242Z",
     "iopub.status.busy": "2020-11-21T15:10:33.318389Z",
     "iopub.status.idle": "2020-11-21T15:10:33.321287Z",
     "shell.execute_reply": "2020-11-21T15:10:33.321862Z"
    },
    "papermill": {
     "duration": 0.021316,
     "end_time": "2020-11-21T15:10:33.321995",
     "exception": false,
     "start_time": "2020-11-21T15:10:33.300679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# based on pre-trained base\n",
    "image_size = (218, 178)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T15:10:33.355660Z",
     "iopub.status.busy": "2020-11-21T15:10:33.354955Z",
     "iopub.status.idle": "2020-11-21T15:10:33.359621Z",
     "shell.execute_reply": "2020-11-21T15:10:33.359008Z"
    },
    "papermill": {
     "duration": 0.023827,
     "end_time": "2020-11-21T15:10:33.359720",
     "exception": false,
     "start_time": "2020-11-21T15:10:33.335893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_datagen = CutOutDataGenerator(rotation_range = 6,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   rescale = 1./255.,\n",
    "                                   horizontal_flip = True,\n",
    "                                   cutout_size=20, n_squares=2)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T15:10:33.425527Z",
     "iopub.status.busy": "2020-11-21T15:10:33.420297Z",
     "iopub.status.idle": "2020-11-21T15:10:38.217762Z",
     "shell.execute_reply": "2020-11-21T15:10:38.216865Z"
    },
    "papermill": {
     "duration": 4.844322,
     "end_time": "2020-11-21T15:10:38.217879",
     "exception": false,
     "start_time": "2020-11-21T15:10:33.373557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14047 validated image filenames belonging to 2 classes.\n",
      "Found 3445 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                            x_col=train_df.columns[0],\n",
    "                                            y_col=train_df.columns[1],\n",
    "                                            batch_size=batch_size,\n",
    "                                            seed=42,\n",
    "                                            shuffle=True,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            target_size=image_size,\n",
    "                                            color_mode='rgb')\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(dataframe=test_df,\n",
    "                                            x_col=test_df.columns[0],\n",
    "                                            y_col=test_df.columns[1],\n",
    "                                            batch_size=batch_size,\n",
    "                                            seed=42,\n",
    "                                            shuffle=True,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            target_size=image_size,\n",
    "                                            color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T15:10:38.249362Z",
     "iopub.status.busy": "2020-11-21T15:10:38.248681Z",
     "iopub.status.idle": "2020-11-21T15:10:45.161975Z",
     "shell.execute_reply": "2020-11-21T15:10:45.162497Z"
    },
    "papermill": {
     "duration": 6.930944,
     "end_time": "2020-11-21T15:10:45.162687",
     "exception": false,
     "start_time": "2020-11-21T15:10:38.231743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inceptionv3_celeba = \"../input/image-recognition-gender-detection-inceptionv3/weights.best.inc.male.hdf5\"\n",
    "pretrained_model = load_model(inceptionv3_celeba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014722,
     "end_time": "2020-11-21T15:10:45.192394",
     "exception": false,
     "start_time": "2020-11-21T15:10:45.177672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T15:10:45.229827Z",
     "iopub.status.busy": "2020-11-21T15:10:45.229086Z",
     "iopub.status.idle": "2020-11-21T15:10:45.233737Z",
     "shell.execute_reply": "2020-11-21T15:10:45.233163Z"
    },
    "papermill": {
     "duration": 0.026396,
     "end_time": "2020-11-21T15:10:45.233856",
     "exception": false,
     "start_time": "2020-11-21T15:10:45.207460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('cutout_model_fold4.h5', \n",
    "                             monitor='val_accuracy', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max')\n",
    "\n",
    "def step_decay(epoch):\n",
    "    if epoch < 10:\n",
    "        lrate = 0.01\n",
    "    else:\n",
    "        initial_lrate = 0.005\n",
    "        drop = 0.5\n",
    "        epochs_drop = 10.0\n",
    "        lrate = initial_lrate * math.pow(drop, \n",
    "                math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "  \n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list= [checkpoint, lrate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T15:10:45.266660Z",
     "iopub.status.busy": "2020-11-21T15:10:45.266014Z",
     "iopub.status.idle": "2020-11-21T15:10:45.269963Z",
     "shell.execute_reply": "2020-11-21T15:10:45.270479Z"
    },
    "papermill": {
     "duration": 0.022788,
     "end_time": "2020-11-21T15:10:45.270670",
     "exception": false,
     "start_time": "2020-11-21T15:10:45.247882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_STEP_SIZE = train_generator.n//train_generator.batch_size\n",
    "VAL_STEP_SIZE = val_generator.n//val_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T15:10:45.307854Z",
     "iopub.status.busy": "2020-11-21T15:10:45.306802Z",
     "iopub.status.idle": "2020-11-21T18:41:14.229470Z",
     "shell.execute_reply": "2020-11-21T18:41:14.228634Z"
    },
    "papermill": {
     "duration": 12628.944714,
     "end_time": "2020-11-21T18:41:14.229625",
     "exception": false,
     "start_time": "2020-11-21T15:10:45.284911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.2814 - accuracy: 0.8793\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76256, saving model to cutout_model_fold4.h5\n",
      "438/438 [==============================] - 462s 1s/step - loss: 0.2814 - accuracy: 0.8793 - val_loss: 0.9045 - val_accuracy: 0.7626\n",
      "Epoch 2/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.1717 - accuracy: 0.9353\n",
      "Epoch 00002: val_accuracy improved from 0.76256 to 0.87909, saving model to cutout_model_fold4.h5\n",
      "438/438 [==============================] - 419s 957ms/step - loss: 0.1717 - accuracy: 0.9353 - val_loss: 0.3003 - val_accuracy: 0.8791\n",
      "Epoch 3/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.1371 - accuracy: 0.9478\n",
      "Epoch 00003: val_accuracy did not improve from 0.87909\n",
      "438/438 [==============================] - 418s 954ms/step - loss: 0.1371 - accuracy: 0.9478 - val_loss: 0.5310 - val_accuracy: 0.8481\n",
      "Epoch 4/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9603\n",
      "Epoch 00004: val_accuracy improved from 0.87909 to 0.89077, saving model to cutout_model_fold4.h5\n",
      "438/438 [==============================] - 425s 971ms/step - loss: 0.1068 - accuracy: 0.9603 - val_loss: 0.2739 - val_accuracy: 0.8908\n",
      "Epoch 5/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.9682\n",
      "Epoch 00005: val_accuracy did not improve from 0.89077\n",
      "438/438 [==============================] - 417s 951ms/step - loss: 0.0906 - accuracy: 0.9682 - val_loss: 0.3300 - val_accuracy: 0.8864\n",
      "Epoch 6/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9692\n",
      "Epoch 00006: val_accuracy did not improve from 0.89077\n",
      "438/438 [==============================] - 417s 952ms/step - loss: 0.0865 - accuracy: 0.9692 - val_loss: 0.2976 - val_accuracy: 0.8841\n",
      "Epoch 7/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9761\n",
      "Epoch 00007: val_accuracy improved from 0.89077 to 0.89282, saving model to cutout_model_fold4.h5\n",
      "438/438 [==============================] - 428s 978ms/step - loss: 0.0665 - accuracy: 0.9761 - val_loss: 0.3065 - val_accuracy: 0.8928\n",
      "Epoch 8/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9787\n",
      "Epoch 00008: val_accuracy improved from 0.89282 to 0.89807, saving model to cutout_model_fold4.h5\n",
      "438/438 [==============================] - 415s 946ms/step - loss: 0.0615 - accuracy: 0.9787 - val_loss: 0.2747 - val_accuracy: 0.8981\n",
      "Epoch 9/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9788\n",
      "Epoch 00009: val_accuracy did not improve from 0.89807\n",
      "438/438 [==============================] - 442s 1s/step - loss: 0.0583 - accuracy: 0.9788 - val_loss: 0.4412 - val_accuracy: 0.8805\n",
      "Epoch 10/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9822\n",
      "Epoch 00010: val_accuracy improved from 0.89807 to 0.89866, saving model to cutout_model_fold4.h5\n",
      "438/438 [==============================] - 414s 944ms/step - loss: 0.0498 - accuracy: 0.9822 - val_loss: 0.2934 - val_accuracy: 0.8987\n",
      "Epoch 11/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9882\n",
      "Epoch 00011: val_accuracy improved from 0.89866 to 0.91326, saving model to cutout_model_fold4.h5\n",
      "438/438 [==============================] - 412s 940ms/step - loss: 0.0310 - accuracy: 0.9882 - val_loss: 0.2832 - val_accuracy: 0.9133\n",
      "Epoch 12/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9934\n",
      "Epoch 00012: val_accuracy did not improve from 0.91326\n",
      "438/438 [==============================] - 410s 936ms/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.3230 - val_accuracy: 0.9071\n",
      "Epoch 13/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9931\n",
      "Epoch 00013: val_accuracy improved from 0.91326 to 0.91443, saving model to cutout_model_fold4.h5\n",
      "438/438 [==============================] - 419s 956ms/step - loss: 0.0189 - accuracy: 0.9931 - val_loss: 0.3141 - val_accuracy: 0.9144\n",
      "Epoch 14/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9951\n",
      "Epoch 00014: val_accuracy did not improve from 0.91443\n",
      "438/438 [==============================] - 416s 950ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.3460 - val_accuracy: 0.9095\n",
      "Epoch 15/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9953\n",
      "Epoch 00015: val_accuracy did not improve from 0.91443\n",
      "438/438 [==============================] - 421s 960ms/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.3185 - val_accuracy: 0.9136\n",
      "Epoch 16/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9951\n",
      "Epoch 00016: val_accuracy improved from 0.91443 to 0.91735, saving model to cutout_model_fold4.h5\n",
      "438/438 [==============================] - 416s 951ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.3173 - val_accuracy: 0.9173\n",
      "Epoch 17/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9954\n",
      "Epoch 00017: val_accuracy did not improve from 0.91735\n",
      "438/438 [==============================] - 428s 977ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.3847 - val_accuracy: 0.9025\n",
      "Epoch 18/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9955\n",
      "Epoch 00018: val_accuracy did not improve from 0.91735\n",
      "438/438 [==============================] - 415s 948ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 0.3555 - val_accuracy: 0.9098\n",
      "Epoch 19/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9959\n",
      "Epoch 00019: val_accuracy did not improve from 0.91735\n",
      "438/438 [==============================] - 416s 950ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.3826 - val_accuracy: 0.9068\n",
      "Epoch 20/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9970\n",
      "Epoch 00020: val_accuracy did not improve from 0.91735\n",
      "438/438 [==============================] - 415s 948ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.3673 - val_accuracy: 0.9127\n",
      "Epoch 21/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9964\n",
      "Epoch 00021: val_accuracy did not improve from 0.91735\n",
      "438/438 [==============================] - 409s 934ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.3913 - val_accuracy: 0.9080\n",
      "Epoch 22/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9968\n",
      "Epoch 00022: val_accuracy did not improve from 0.91735\n",
      "438/438 [==============================] - 413s 943ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.3805 - val_accuracy: 0.9124\n",
      "Epoch 23/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9974\n",
      "Epoch 00023: val_accuracy did not improve from 0.91735\n",
      "438/438 [==============================] - 419s 958ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.3947 - val_accuracy: 0.9092\n",
      "Epoch 24/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9976\n",
      "Epoch 00024: val_accuracy did not improve from 0.91735\n",
      "438/438 [==============================] - 420s 958ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.3667 - val_accuracy: 0.9133\n",
      "Epoch 25/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9971\n",
      "Epoch 00025: val_accuracy did not improve from 0.91735\n",
      "438/438 [==============================] - 423s 965ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.3542 - val_accuracy: 0.9156\n",
      "Epoch 26/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9973\n",
      "Epoch 00026: val_accuracy did not improve from 0.91735\n",
      "438/438 [==============================] - 425s 969ms/step - loss: 0.0072 - accuracy: 0.9973 - val_loss: 0.3854 - val_accuracy: 0.9086\n",
      "Epoch 27/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 00027: val_accuracy did not improve from 0.91735\n",
      "438/438 [==============================] - 420s 959ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.3897 - val_accuracy: 0.9133\n",
      "Epoch 28/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9973\n",
      "Epoch 00028: val_accuracy did not improve from 0.91735\n",
      "438/438 [==============================] - 413s 944ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.4006 - val_accuracy: 0.9103\n",
      "Epoch 29/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9975\n",
      "Epoch 00029: val_accuracy did not improve from 0.91735\n",
      "438/438 [==============================] - 410s 935ms/step - loss: 0.0066 - accuracy: 0.9975 - val_loss: 0.4179 - val_accuracy: 0.9080\n",
      "Epoch 30/30\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9977\n",
      "Epoch 00030: val_accuracy did not improve from 0.91735\n",
      "438/438 [==============================] - 403s 921ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.4023 - val_accuracy: 0.9112\n"
     ]
    }
   ],
   "source": [
    "history = pretrained_model.fit(train_generator,\n",
    "          steps_per_epoch=TRAIN_STEP_SIZE,\n",
    "          epochs=30,\n",
    "          validation_data=val_generator,\n",
    "          validation_steps=VAL_STEP_SIZE,\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T18:41:23.556156Z",
     "iopub.status.busy": "2020-11-21T18:41:23.555286Z",
     "iopub.status.idle": "2020-11-21T18:41:23.558813Z",
     "shell.execute_reply": "2020-11-21T18:41:23.558271Z"
    },
    "papermill": {
     "duration": 4.768762,
     "end_time": "2020-11-21T18:41:23.558941",
     "exception": false,
     "start_time": "2020-11-21T18:41:18.790179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(\"fold4_validation.npy\", history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 12667.483435,
   "end_time": "2020-11-21T18:41:30.012262",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-21T15:10:22.528827",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
